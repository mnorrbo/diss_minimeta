knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(metafor)
install.packages("metafor")
install.packages("metafor")
install.packages("remotes")
remotes::install_github("wviechtb/metafor")
library(tidyverse)
library(metafor)
library(tidyverse)
library(metafor)
library(purrr)
library(colorspace)
library(tidyverse)
library(metafor)
library(purrr)
library(colorspace)
sim_func <- function(n, d = 0) {
dat <- tibble(
grp = rep(LETTERS[1:2], each = n),
score = c(rnorm(n, d, 1), rnorm(n, 0, 1)
))
#t-test on simulated data
myt <- t.test(score ~ grp, dat)
#get p-value
p <- myt$p.value
#get effect size
es <- cohens_d(myt$statistic[[1]], n, n)
list("p" = p, "es" = es)
}
cohens_d <- function(t, n1, n2 = n1){
t*sqrt(1/n1 + 1/n2)
}
var_d <- function(d,n){
df <- (2*n-2)
(2/n+(d^2)/(2*df)) * ((2*n)/(df))
}
mini_meta <- function(n.studies, # no. of studies
d, # effect size
n, # sample size (per group)
method = "HE"){ # method for rma()
study.ps <- vector() # vector for p-values
study.effects <- vector() # vector for effect sizes
study.var <- vector() # vector for variances
for (i in 1:n.studies) { # loop until specified number of studies is reached
study <- sim_func(n, d) # simulate study with n sample and d effect size
study.ps[i] <- study$p # p-values in vector
study.effects[i] <- study$es # effect sizes in vector
study.var[i] <- var_d(study.effects[i], n) # variances in vector
}
# run internal meta-analysis
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
data.frame( # add results to a data.frame
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # internal meta-analysis results
p = minimeta$pval, # meta-analysed p-value
es = minimeta$beta[[1]] # meta-analysed effect size
)
}
p_bound_meta <- function(n.studies, # no. of studies
d, # effect size
n, # sample size
method = "HE", # method for rma()
pmax.first = .05, # threshold for first p
pmax.last = .05){ # threshold for last p
study.ps <- vector() # vector for p-values
study.effects <- vector() # vector for effect sizes
study.var <- vector() # vector for variances
study <- sim_func(n, d) # simulate first study
study.ps[1] <- study$p
study.effects[1] <- study$es
study.var[1] <- var_d(study.effects[1], n)
if (study.ps[1] >= pmax.first) { # if first study p > pmax.first
tbl <- data.frame( # create table of results
study = 1,
p = study.ps,
es = study.effects
)
return(tbl)
}
# else, keep running studies until n.studies
for (i in 2:n.studies) {
study <- sim_func(n, d)
study.ps[i] <- study$p
study.effects[i] <- study$es
study.var[i] <- var_d(study.effects[i], n)
# unless p < pmax.last, then stop running more studies
if (study$p < pmax.last) break
}
# run internal meta-analysis
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
data.frame( # add results to a dataframe
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # meta-analysis results
p = minimeta$pval, # meta-analysed p-value
es = minimeta$beta[[1]] # meta-analyseds effect size
)
}
meta_hack <- function(n.studies, # no. of studies
d, # effect size
n, # sample size
method = "HE", # method for rma()
pmax.first = .05, # first p threshold
minitarget = .05){ # meta-analysed p threshold
# setting up results vectors
study.ps <- vector()
study.effects <- vector()
study.var <- vector()
# results of first study
study <- sim_func(n, d)
study.ps[1] <- study$p
study.effects[1] <- study$es
study.var[1] <- var_d(study.effects[1], n)
if (study.ps[1] >= pmax.first) { # if first study p > pmax.first
tbl <- data.frame( # create table of results
study = 1,
p = study.ps,
es = study.effects)
return(tbl)
}
# else, keep running studies until n.studies or
for (i in 2:n.studies) {
study <- sim_func(n, d)
study.ps[i] <- study$p
study.effects[i] <- study$es
study.var[i] <- var_d(study.effects[i], n)
# meta p < minitarget
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
if (minimeta$pval < minitarget) break
}
data.frame( # add results to data frame
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # meta-analysis results
p = minimeta$pval, # meta p
es = minimeta$beta[[1]] # meta es
)
}
params <- crossing( # all simulation parameters are fully crossed
n.studies = 5,
n = seq(50, 500, 50),
d = seq(0.1, 1, 0.1),
iter = 1:10,
method = c("HE", "FE")
)
tmp <- purrr::pmap_dfr(params, function(...) {
dots <- list(...)
mini_meta(n.studies = dots$n.studies,
d = dots$d,
n = dots$n,
method = dots$method) %>%
mutate(!!!dots)
})
save(tmp, file = "nohack_tmp.RData")
set.seed(1337)
params <- crossing( # all simulation parameters are fully crossed
n.studies = 4,
n = seq(20, 500, 20),
d = seq(0.1, 1, 0.1),
iter = 1:10000,
method = c("HE", "FE")
)
tmp <- purrr::pmap_dfr(params, function(...) {
dots <- list(...)
mini_meta(n.studies = dots$n.studies,
d = dots$d,
n = dots$n,
method = dots$method) %>%
mutate(!!!dots)
})
knitr::opts_chunk$set(echo = TRUE)
# load saved simulation results from chunk above
load("nohack_tmp.RData")
# create dataframe of all study sizes
nohack_dat <- nohack_tmp %>%
filter(study == 0) %>%
group_by(n, method, d, n.studies) %>%
summarise(power = mean(p < .05)) %>% # calculate power
ungroup()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(metafor)
library(colorspace)
sessionInfo()
sim_func <- function(n, d = 0) {
dat <- tibble(
grp = rep(LETTERS[1:2], each = n),
score = c(rnorm(n, d, 1), rnorm(n, 0, 1)
))
#t-test on simulated data
myt <- t.test(score ~ grp, dat)
#get p-value
p <- myt$p.value
#get effect size
es <- cohens_d(myt$statistic[[1]], n, n)
list("p" = p, "es" = es)
}
cohens_d <- function(t, n1, n2 = n1){
t*sqrt(1/n1 + 1/n2)
}
var_d <- function(d,n){
df <- (2*n-2)
(2/n+(d^2)/(2*df)) * ((2*n)/(df))
}
mini_meta <- function(n.studies, # no. of studies
d, # effect size
n, # sample size (per group)
method = "HE"){ # method for rma()
study.ps <- vector() # vector for p-values
study.effects <- vector() # vector for effect sizes
study.var <- vector() # vector for variances
for (i in 1:n.studies) { # loop until specified number of studies is reached
study <- sim_func(n, d) # simulate study with n sample and d effect size
study.ps[i] <- study$p # p-values in vector
study.effects[i] <- study$es # effect sizes in vector
study.var[i] <- var_d(study.effects[i], n) # variances in vector
}
# run internal meta-analysis
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
data.frame( # add results to a data.frame
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # internal meta-analysis results
p = minimeta$pval, # meta-analysed p-value
es = minimeta$beta[[1]] # meta-analysed effect size
)
}
p_bound_meta <- function(n.studies, # no. of studies
d, # effect size
n, # sample size
method = "HE", # method for rma()
pmax.first = .05, # threshold for first p
pmax.last = .05){ # threshold for last p
study.ps <- vector() # vector for p-values
study.effects <- vector() # vector for effect sizes
study.var <- vector() # vector for variances
study <- sim_func(n, d) # simulate first study
study.ps[1] <- study$p
study.effects[1] <- study$es
study.var[1] <- var_d(study.effects[1], n)
if (study.ps[1] >= pmax.first) { # if first study p > pmax.first
tbl <- data.frame( # create table of results
study = 1,
p = study.ps,
es = study.effects
)
return(tbl)
}
# else, keep running studies until n.studies
for (i in 2:n.studies) {
study <- sim_func(n, d)
study.ps[i] <- study$p
study.effects[i] <- study$es
study.var[i] <- var_d(study.effects[i], n)
# unless p < pmax.last, then stop running more studies
if (study$p < pmax.last) break
}
# run internal meta-analysis
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
data.frame( # add results to a dataframe
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # meta-analysis results
p = minimeta$pval, # meta-analysed p-value
es = minimeta$beta[[1]] # meta-analyseds effect size
)
}
meta_hack <- function(n.studies, # no. of studies
d, # effect size
n, # sample size
method = "HE", # method for rma()
pmax.first = .05, # first p threshold
minitarget = .05){ # meta-analysed p threshold
# setting up results vectors
study.ps <- vector()
study.effects <- vector()
study.var <- vector()
# results of first study
study <- sim_func(n, d)
study.ps[1] <- study$p
study.effects[1] <- study$es
study.var[1] <- var_d(study.effects[1], n)
if (study.ps[1] >= pmax.first) { # if first study p > pmax.first
tbl <- data.frame( # create table of results
study = 1,
p = study.ps,
es = study.effects)
return(tbl)
}
# else, keep running studies until n.studies or
for (i in 2:n.studies) {
study <- sim_func(n, d)
study.ps[i] <- study$p
study.effects[i] <- study$es
study.var[i] <- var_d(study.effects[i], n)
# meta p < minitarget
minimeta <- rma(yi = study.effects, vi = study.var, method = method)
if (minimeta$pval < minitarget) break
}
data.frame( # add results to data frame
study = 1:length(study.ps),
p = study.ps,
es = study.effects
) %>%
add_row(
study = 0, # meta-analysis results
p = minimeta$pval, # meta p
es = minimeta$beta[[1]] # meta es
)
}
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
# load saved simulation results from chunk above
load("nohack_tmp.RData")
# create dataframe of all study sizes
nohack_dat <- nohack_tmp %>%
filter(study == 0) %>%
group_by(n, method, d, n.studies) %>%
summarise(power = mean(p < .05)) %>% # calculate power
ungroup()
library(tidyverse)
library(metafor)
library(colorspace)
params <- crossing( # all simulation parameters are fully crossed
n.studies = 4,
n = seq(20, 500, 20),
d = 0,
iter = 1:1000,
method = c("HE", "FE")
)
nohack_tmp <- purrr::pmap_dfr(params, function(...) {
dots <- list(...)
mini_meta(n.studies = dots$n.studies,
d = dots$d,
n = dots$n,
method = dots$method) %>%
mutate(!!!dots)
})
# load saved simulation results from chunk above
load("nohack_tmp.RData")
# create dataframe of all study sizes
nohack_dat <- nohack_tmp %>%
filter(study == 0) %>%
group_by(n, method, d, n.studies) %>%
summarise(power = mean(p < .05)) %>% # calculate power
ungroup()
# colourblind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# renaming figure legend
nohack_dat <- nohack_dat %>%
rename(Method = method) %>%
mutate(Method = recode(Method,
"HE" = "Random effects",
"FE" = "Fixed effect"))
# plot
ggplot(nohack_dat, aes(n, power)) +
geom_line(aes(linetype = Method,
color = Method), size=1.5) +
scale_y_continuous(limits = c(0, 1),
breaks = seq(0, 1, 0.1)) +
scale_x_continuous(limits = c(20, 500),
breaks = seq(50, 500, 50)) +
geom_hline(yintercept = 0.05, size = 1,
linetype = "longdash") +
scale_color_manual(values=cbPalette) +
theme_bw() +
theme(axis.title = element_text(size = 15),
title = element_text(size = 15),
axis.text = element_text(size = 10),
axis.ticks.x = element_line(size = 1),
axis.text.x =element_text(size=12),
axis.text.y = element_text(size=12),
legend.text = element_text(size = 12)) +
labs(x = "Sample size (n)",
y = "False Positive Rate (FPR)",
title = "First and last p-values < 0.05") +
annotate("text", x = 120, y = 0.025,
label = "Nominal FPR 0.05", size = 5)
# ggsave("nohack_fpr_plot.png", width = 10, height = 7)
